---
title: "Browser Extension"
description: "Real-time risk assessment for Gemini, Claude, and ChatGPT with Orcho's Chrome Extension"
icon: "chrome"
---

Orcho's Chrome Extension provides real-time risk assessment for AI prompts across Google Gemini, Claude (web), and ChatGPT. Get instant risk scores and warnings before submitting potentially dangerous prompts, protecting your organization from data leaks and risky operations.

## Features

<CardGroup cols={2}>
  <Card title="Multi-Platform Support" icon="globe">
    Works with Gemini, Claude, and ChatGPT
  </Card>
  <Card title="Real-Time Analysis" icon="bolt">
    Risk assessment happens as you type
  </Card>
  <Card title="Smart Warnings" icon="shield-halved">
    Visual alerts for high-risk prompts before submission
  </Card>
  <Card title="Click-to-Block" icon="hand">
    One-click blocking of critical-risk prompts
  </Card>
</CardGroup>

## Supported Platforms

<Tabs>
  <Tab title="Google Gemini">
    **Supported:**

    - âœ… gemini.google.com
    - âœ… Gemini Advanced
    - âœ… Gemini Pro
    - âœ… All conversation modes

    **Features:**

    - Real-time risk scoring as you type
    - Warning banner for high-risk prompts
    - Prompt blocking for critical risks
    - Risk history tracking
  </Tab>
  <Tab title="Claude (Web)">
    **Supported:**

    - âœ… claude.ai
    - âœ… Claude Sonnet
    - âœ… Claude Opus
    - âœ… Claude Projects

    **Features:**

    - Inline risk indicators
    - Pre-submission warnings
    - Context-aware analysis (with Projects)
    - Artifact risk assessment
  </Tab>
  <Tab title="ChatGPT">
    **Supported:**

    - âœ… chat.openai.com
    - âœ… ChatGPT Plus
    - âœ… ChatGPT Team
    - âœ… GPT-4 models

    **Features:**

    - Real-time risk display
    - Warning modals for high-risk
    - Automatic prompt sanitization suggestions
    - Conversation-level risk tracking
  </Tab>
</Tabs>

## Installation

<Steps>
  <Step title="Install from Chrome Web Store">
    Visit the [Chrome Web Store](https://chrome.google.com/webstore) and search for "Orcho Risk Assessment"

    Or click: [Install Orcho Extension](https://chrome.google.com/webstore/detail/orcho)

    <Check>
      Works on any Chromium-based browser: Chrome, Edge, Brave, Arc
    </Check>
  </Step>
  <Step title="Pin the extension">
    Click the puzzle icon in your browser toolbar and pin Orcho for easy access
  </Step>
  <Step title="Contact for API key">
    Email [support@orcho.ai](mailto:support@orcho.ai) to request an API key for your organization
  </Step>
  <Step title="Configure the extension">
    Click the Orcho icon and enter your API key:

    <Tabs>
      <Tab title="Step-by-step">
        1. Click Orcho extension icon
        2. Click "Settings"
        3. Paste your API key
        4. Click "Save"
        5. Refresh AI platform tabs
      </Tab>
      <Tab title="First-time setup">
        On first install, you'll see:

        ```
        Welcome to Orcho!
        
        To get started, you'll need an API key.
        
        Contact support@orcho.ai to request one.
        
        [ Enter API Key ]  [ Save ]
        ```
      </Tab>
    </Tabs>
  </Step>
  <Step title="Test the extension">
    Go to claude.ai, gemini.google.com, or chat.openai.com and type a high-risk prompt:

    ```
    Delete all records from the production database
    ```

    You should see a risk indicator appear
  </Step>
</Steps>

## How It Works

<Steps>
  <Step title="You start typing">
    Begin writing a prompt in Gemini, Claude, or ChatGPT
  </Step>
  <Step title="Real-time analysis">
    Orcho analyzes your prompt as you type (with a 500ms debounce to avoid excessive API calls)
  </Step>
  <Step title="Risk score displayed">
    A risk indicator appears showing:

    - Risk score (0.0-1.0)
    - Risk level (minimal, low, medium, high, critical)
    - Color-coded badge (green â†’ red)
  </Step>
  <Step title="Warnings for high risk">
    If risk â‰¥ 0.6 (high), a warning banner appears:

    ```
    âš ï¸  HIGH RISK DETECTED (Score: 0.78)
    
    This prompt may:
    â€¢ Expose sensitive data
    â€¢ Cause irreversible changes
    â€¢ Violate security policies
    
    Suggestions:
    â€¢ Remove specific identifiers
    â€¢ Add safety constraints
    â€¢ Review with security team
    
    [ Modify Prompt ]  [ Proceed Anyway ]
    ```
  </Step>
  <Step title="Blocking for critical risk">
    If risk â‰¥ 0.8 (critical), prompt submission is blocked:

    ```
    ğŸ›‘ CRITICAL RISK - SUBMISSION BLOCKED
    
    This prompt has been blocked due to critical risk factors:
    â€¢ Data Sensitivity: 0.95 (CRITICAL)
    â€¢ Potential for irreversible damage
    
    You cannot submit this prompt. Please:
    â€¢ Rephrase to remove sensitive data
    â€¢ Contact security team for approval
    â€¢ Use a different approach
    
    [ Edit Prompt ]  [ Contact Security ]
    ```
  </Step>
</Steps>

## Visual Indicators

### Risk Badges

The extension shows risk level with color-coded badges:

<ResponseExample>

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Your prompt here...                     â”‚
â”‚                                         â”‚
â”‚                    [âœ“ MINIMAL] 0.12    â”‚ â† Green badge
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Drop the users table                    â”‚
â”‚                                         â”‚
â”‚                    [âš ï¸ CRITICAL] 0.92   â”‚ â† Red badge
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</ResponseExample>

### Risk Level Colors

| Risk Level | Score Range | Badge Color | Behavior       |
| ---------- | ----------- | ----------- | -------------- |
| Minimal    | \< 0.2      | ğŸŸ¢ Green    | Allow          |
| Low        | 0.2 - 0.39  | ğŸŸ¡ Yellow   | Allow          |
| Medium     | 0.4 - 0.59  | ğŸŸ  Orange   | Warn           |
| High       | 0.6 - 0.79  | ğŸ”´ Red      | Strong warning |
| Critical   | â‰¥ 0.8       | â›” Dark Red  | Block          |

## Configuration Options

### Risk Thresholds

Customize when warnings and blocks occur:

<ParamField path="warning_threshold" default="0.6" type="number">
  Risk score that triggers warning banners

  Default: `0.6` (high risk)
</ParamField>

<ParamField path="blocking_threshold" default="0.8" type="number">
  Risk score that blocks prompt submission

  Default: `0.8` (critical risk)
</ParamField>

<ParamField path="show_suggestions" default="true" type="boolean">
  Show suggestions for safer alternatives

  Default: `true`
</ParamField>

### Notification Settings

<ParamField path="desktop_notifications" default="false" type="boolean">
  Show desktop notifications for high-risk prompts

  Default: `false`
</ParamField>

<ParamField path="sound_alerts" default="false" type="boolean">
  Play sound for critical-risk prompts

  Default: `false`
</ParamField>

<ParamField path="log_prompts" default="true" type="boolean">
  Log all assessed prompts for audit purposes

  Default: `true`
</ParamField>

### Platform Settings

<ParamField path="enabled_platforms" default='["gemini", "claude", "chatgpt"]' type="array">
  Which AI platforms to monitor

  Options: `"gemini"`, `"claude"`, `"chatgpt"`
</ParamField>

<ParamField path="auto_block" default="true" type="boolean">
  Automatically block critical-risk prompts

  Default: `true`
</ParamField>

<ParamField path="require_justification" default="false" type="boolean">
  Require written justification for high-risk prompts

  Default: `false`
</ParamField>

## Example Scenarios

### Scenario 1: Database Deletion

<Steps>
  <Step title="User types prompt">
    ```
    Delete all user accounts that haven't logged in this year
    ```
  </Step>
  <Step title="Risk assessment">
    ```
    âš ï¸  HIGH RISK (Score: 0.74)
    
    Risk Factors:
    â€¢ Data Sensitivity: 0.88
    â€¢ Input Clarity: 0.65
    â€¢ Blast Radius: 0.68
    ```
  </Step>
  <Step title="Warning displayed">
    ```
    This prompt may cause irreversible data loss.
    
    Suggestions:
    â€¢ Use SELECT first to preview affected records
    â€¢ Export data before deletion
    â€¢ Use soft delete (mark as inactive) instead
    â€¢ Add WHERE clause with specific date
    â€¢ Require manual confirmation
    
    [ Modify Prompt ]  [ Proceed with Caution ]
    ```
  </Step>
</Steps>

### Scenario 2: Sensitive Data Exposure

<Steps>
  <Step title="User types prompt">
    ```
    Analyze this customer data: 
    Name: John Doe
    SSN: 123-45-6789
    Credit Card: 4532-1234-5678-9012
    ```
  </Step>
  <Step title="Risk assessment">
    ```
    ğŸ›‘ CRITICAL RISK (Score: 0.98)
    
    Risk Factors:
    â€¢ Data Sensitivity: 0.99 (PII detected)
    â€¢ Input Clarity: 0.95
    ```
  </Step>
  <Step title="Submission blocked">
    ```
    SUBMISSION BLOCKED
    
    This prompt contains:
    â€¢ Social Security Number
    â€¢ Credit card information
    â€¢ Personally Identifiable Information (PII)
    
    This violates data security policies.
    
    How to proceed:
    â€¢ Remove sensitive data
    â€¢ Use anonymized test data
    â€¢ Mask sensitive fields (XXX-XX-6789)
    â€¢ Contact compliance team
    
    [ Edit Prompt ]  [ Request Compliance Override ]
    ```
  </Step>
</Steps>

### Scenario 3: Safe Code Request

<Steps>
  <Step title="User types prompt">
    ```
    Write a function to calculate the Fibonacci sequence in Python
    ```
  </Step>
  <Step title="Risk assessment">
    ```
    âœ“ MINIMAL RISK (Score: 0.08)
    
    This prompt is safe to proceed.
    ```
  </Step>
  <Step title="No warning">
    Green badge displayed, user can submit immediately without warnings
  </Step>
</Steps>

## Audit & Compliance

### Prompt Logging

All assessed prompts are logged (if enabled) with:

```json
{
  "timestamp": "2026-01-08T14:30:00Z",
  "platform": "claude",
  "user_email": "john.doe@company.com",
  "prompt": "Delete old records...",
  "risk_score": 0.74,
  "risk_level": "high",
  "action_taken": "warned",
  "user_proceeded": false
}
```

### Export Reports

Export risk assessment reports:

1. Navigate to Orcho dashboard
1. Click "Reports"
3. Select date range
4. Click "Export CSV" or "Export JSON"

**Report includes:**

- All assessed prompts
- Risk scores and levels
- User actions (modified, proceeded, blocked)
- Timestamps and platforms

### Compliance Dashboard

View organization-wide metrics:

- Total prompts assessed
- High-risk attempts
- Blocked prompts
- Most common risk factors
- Users with most high-risk prompts

Access at: [{companyName}.orcho.ai/compliance](https://app.orcho.ai/compliance)

## Privacy & Security

<Warning>
  **Your prompts are processed securely:**
</Warning>

<Steps>
  <Step title="TLS encryption">
    All API calls use TLS 1.3 encryption
  </Step>
  <Step title="No storage">
    Prompts are analyzed in real-time and not stored on Orcho servers (unless logging is enabled by admin)
  </Step>
  <Step title="Local processing option">
    Enterprise customers can run risk assessment locally (contact sales)
  </Step>
  <Step title="Zero-knowledge architecture">
    Orcho cannot read your API keys - they're stored encrypted in browser storage
  </Step>
</Steps>

### What Data is Sent

When you type a prompt, only the following is sent to Orcho:

```json
{
  "prompt": "Your prompt text",
  "platform": "claude",
  "user_id": "hashed_user_id"
}
```

**Not sent:**

- âŒ Your API keys for AI platforms
- âŒ Previous conversation history
- âŒ Personal information
- âŒ Browser history

## Troubleshooting

<AccordionGroup>
  <Accordion title="Extension not showing risk scores">
    **Check extension is active:**

    1. Click puzzle icon â†’ Check Orcho is enabled
    2. Refresh the AI platform page
    3. Check extension icon - should be colored (not gray)

    **Verify API key:**

    1. Click Orcho icon â†’ Settings
    2. Check API key is entered correctly
    3. Click "Test Connection" to verify

    **Platform compatibility:**

    1. Ensure you're on supported domain
    2. Check extension permissions in chrome://extensions
  </Accordion>
  <Accordion title="API key errors">
    **Invalid key:**

    - Contact [support@orcho.ai](mailto:support@orcho.ai)
    - Check for extra spaces
    - Try re-entering the key

    **Rate limits:**

    - Contact support to check quota
    - Reduce typing speed (extension debounces at 500ms)
    - Upgrade plan for higher limits
  </Accordion>
  <Accordion title="Risk scores seem incorrect">
    **False positives:**

    - Click "Report Incorrect" button on warning
    - Provide feedback to help us improve
    - Adjust thresholds in settings

    **False negatives:**

    - Report missed high-risk prompts
    - Contact [support@orcho.ai](mailto:support@orcho.ai) with examples
  </Accordion>
  <Accordion title="Extension slowing down browser">
    **Optimize performance:**

    1. Settings â†’ Enable "Lazy loading"
    2. Increase debounce time (500ms â†’ 1000ms)
    3. Disable on less-critical platforms
    4. Clear extension cache

    **Check resource usage:**

    1. Chrome Task Manager (Shift+Esc)
    2. Find "Orcho Extension"
    3. Should use \< 50MB RAM
  </Accordion>
</AccordionGroup>

## Advanced Features

### Custom Risk Rules

Define organization-specific risk rules:

```javascript
// Block prompts containing internal code names
{
  "rule": "keyword_blacklist",
  "keywords": ["ProjectTitan", "AlphaSystem"],
  "action": "block",
  "message": "Internal code names detected"
}

// Warn when requesting production data
{
  "rule": "environment_detection", 
  "patterns": ["production", "prod db", "live server"],
  "action": "warn"
}
```

Configure at: [{companyName}.orcho.ai/rules](https://app.orcho.ai/rules)

### Team Policies

Set policies for your organization:

<Tabs>
  <Tab title="Enforcement Level">
    **Soft Enforcement:**

    - Show warnings but allow override
    - Log overrides for review

    **Hard Enforcement:**

    - Block critical-risk prompts
    - No override option
    - Require security team approval
  </Tab>
  <Tab title="User Roles">
    **Standard Users:**

    - See warnings
    - Can be blocked

    **Power Users:**

    - See warnings
    - Cannot be blocked
    - All prompts logged

    **Admins:**

    - Configure settings
    - View all org prompts
    - Override blocks
  </Tab>
</Tabs>

## Support

Need help with the browser extension?

<CardGroup cols={2}>
  <Card title="Install Extension" icon="chrome" href="https://chrome.google.com/webstore/detail/orcho">
    Download from Chrome Web Store
  </Card>
  <Card title="Get API Key" icon="key" href="mailto:support@orcho.ai">
    Contact us for an API key
  </Card>
  <Card title="Report Issue" icon="bug" href="mailto:support@orcho.ai">
    Report bugs or issues
  </Card>
  <Card title="Request Feature" icon="lightbulb" href="mailto:support@orcho.ai">
    Suggest new features
  </Card>
</CardGroup>

## Next Steps

<Steps>
  <Step title="Install the extension">
    Download from Chrome Web Store
  </Step>
  <Step title="Get your API key">
    Contact [support@orcho.ai](mailto:support@orcho.ai)
  </Step>
  <Step title="Configure settings">
    Set thresholds and enable platforms
  </Step>
  <Step title="Test with sample prompts">
    Try high-risk and low-risk examples
  </Step>
  <Step title="Roll out to team">
    Share installation guide with colleagues
  </Step>
</Steps>